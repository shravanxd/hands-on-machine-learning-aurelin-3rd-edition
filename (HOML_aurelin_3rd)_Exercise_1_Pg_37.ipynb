{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnswZtajBVurXHWb+UlJg3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shravanxd/hands-on-machine-learning-aurelin-3rd-edition/blob/main/(HOML_aurelin_3rd)_Exercise_1_Pg_37.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. How would you define machine learning?**"
      ],
      "metadata": {
        "id": "G_Wn1_fYCaEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning is the science of programming computers so they can learn from data.\n",
        "\n",
        "Scientifically, a computer program is said to learn from an experience E with respect to some task T, measured by a performance P, if its performance on T, as measured by P, improves with experience E."
      ],
      "metadata": {
        "id": "TrnQNalDGayx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Can you name four applications where it shines?**"
      ],
      "metadata": {
        "id": "Qj0CBH6jGuwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML shines in various applications, for example, Classifying SPAM emails, predicting housing prices in a area, a robot using reinforcement learning to perform a task T and learns from its mistake, and using Clustering to group users into various groups or categories."
      ],
      "metadata": {
        "id": "Fo4zKQRhG0v9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What is a labeled training set?**"
      ],
      "metadata": {
        "id": "EPiBH_ZQHgCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A labeled training set refers to an annotated dataset that helps a machine learn which category a given instance of data belongs to. For example, users moving unwanted emails to a SPAM folder can be labeled as SPAM, while other emails can be labeled as ham. This process helps a machine learn from the data and is generally very helpful for supervised learning machine learning algorithms."
      ],
      "metadata": {
        "id": "Beux6seFHhCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What are the two most common supervised tasks?**"
      ],
      "metadata": {
        "id": "GB4kDAbkHhEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two most common supervised learning tasks are regression and classification."
      ],
      "metadata": {
        "id": "CNaDDhqRHhHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Can you name four commond unsupervised tasks?**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XMlVE_8PHhLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering, anomaly detection, association rule learning and dimensionality reduction."
      ],
      "metadata": {
        "id": "3YrGqcQGHhOB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What type of algorithm would you use to allow a robot to walk in various unknown terrains.**\n",
        "\n"
      ],
      "metadata": {
        "id": "ePdd0hc-HhQ4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2ca17f2"
      },
      "source": [
        "Reinforcement learning-based algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What type of algorithm would you use to segment your customer into multiple groups?**"
      ],
      "metadata": {
        "id": "8eFqCAsQLfwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering algorithms (K-means, hierchical clustering, DBSCAN)"
      ],
      "metadata": {
        "id": "r5awLHNCLkdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**8. Would you frame the problem of SPAM detection as a supervised learning problem or an unsupervised learning problem?**\n",
        "\n"
      ],
      "metadata": {
        "id": "sfs_ssvfLkgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I would frame the problem of spam detection as a supervised learning problem, because the model learns from user feedback on which emails have been labeled as spam."
      ],
      "metadata": {
        "id": "DdItXWM2LkjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is an online learning system?**"
      ],
      "metadata": {
        "id": "XRa6hZ8gMsy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In online learning, the system is trained incrementally by feeding it data instances sequentially, either individually or in small groups called mini-batches. Each learning step is fast and inexpensive, allowing the system to adapt to new data on the fly as it arrives."
      ],
      "metadata": {
        "id": "9cb_Lv9MMs2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. What is out-of-core learning?**"
      ],
      "metadata": {
        "id": "a2jBbVmRMs6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the dataset is too large to fit into the system’s main memory at once, we use online learning algorithms to train the models, this method is called out-of-core learning."
      ],
      "metadata": {
        "id": "pApN1iZsNqBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. What type of algorithm relies on a similarity measure to make predictions?**"
      ],
      "metadata": {
        "id": "uVffDyDINqEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instance-based learning algorithms generally rely on a similarity measure; they memorize the training instances and compare them with new instances to make predictions."
      ],
      "metadata": {
        "id": "5p7WS7ihMs9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. What is the difference between a model parameter and a model hyper parameter.**\n"
      ],
      "metadata": {
        "id": "ioQ6ujL5Osjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model parameters are the internal variables learned from the data during training (e.g., weights and biases in neural networks, coefficients in linear regression).\n",
        "\n",
        "Model hyperparameters are external configurations set before training that control how the model learns (e.g., learning rate, number of clusters in K-means, depth of a decision tree)."
      ],
      "metadata": {
        "id": "iKbr335kOsmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. What do model-based algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?**"
      ],
      "metadata": {
        "id": "ZxPhjQLWOspN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model-based learning algorithms search for an optimal value for the model parameters such that the model will generalize well to new instances. We usually train such systems by minimizing a cost function that measures how bad the system is at making predictions on the training data, plus a penalty for model complexity if the model is regularized. To make predictions, we feed the new instance's features into the model's prediction function, using the parameter values found by the learning algorithm."
      ],
      "metadata": {
        "id": "VpwMk4KIOsr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Can you name four of the main challenges in machine learning?**"
      ],
      "metadata": {
        "id": "nTpc63oUOs4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some of the main challenges in machine learning are a lack of data, poor data quality, non-representative data, uninformative features, overly simple models that underfit the training data, and overly complex models that overfit the data."
      ],
      "metadata": {
        "id": "DryWfo0_ZUJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. If your model performs great on the training data but generalizes poorly poorly to new instances, what is happening? Can you name three possible?**"
      ],
      "metadata": {
        "id": "sb6JTi3VZZ7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This condition is called overfitting, where the model learns the training data so well that it fails to generalize to unseen data. One possible reason could be that the training data was not randomly shuffled, leading to biased learning. Common solutions to overfitting include collecting more data, simplifying the model (e.g., choosing a simpler algorithm, reducing the number of parameters or features, or applying regularization), and reducing noise in the training data."
      ],
      "metadata": {
        "id": "Bk4IWW2-ZZ9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. What is a test set, and why would you want to use it?**"
      ],
      "metadata": {
        "id": "C9s7sgYUZaAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In machine learning, the test set is the portion of data that is left out during training and is later used to evaluate the model’s performance. Since the test data already contains labels (ground truth), we withhold these labels during prediction, provide only the input features to the model, and then compare the model’s outputs against the true labels to measure accuracy and generalization. Also, A test set is used to estimate the generalization error that a model will make on new instances, before the model is launched in production.\n"
      ],
      "metadata": {
        "id": "U-SZ6lOCZaCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What is the purpose of the validation set?**"
      ],
      "metadata": {
        "id": "_BV87hz2bFJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A validation set is used to compare models. It makes it possible to select the best model and tune the hyperparameters."
      ],
      "metadata": {
        "id": "7iRwfZPkbFLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. What is the train-dev set, when do you need it, and how do you use it?**"
      ],
      "metadata": {
        "id": "ufJ0JnC5bFQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train-dev set is used when there is a risk of mismatch between the training data and the data used in the validation and test datasets (which should always be as close as possible to the data used once the model is in production). The train-dev set is a part of the training set that's held out (the model is not trained on it). The model is trained on the rest of the training set, and evaluated on both the train-dev set and the validation set. If the model performs well on the training set but not on the train-dev set, then the model is likely overfitting the training set. If it performs well on both the training set and the train-dev set, but not on the validation set, then there is probably a significant data mismatch between the training data and the validation + test data, and you should try to improve the training data to make it look more like the validation + test data."
      ],
      "metadata": {
        "id": "YoECib5QeI34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. What can go wrong if you tune hyperparameters using the test set?**"
      ],
      "metadata": {
        "id": "_ul3fK4keI6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you tune hyperparameters using the test set, you indirectly expose the model to the test data during development. This causes data leakage, making the test set no longer an unbiased measure of generalization. As a result, the reported test accuracy will be overly optimistic and will not reflect real-world performance, since the model has effectively “fit” to the test data."
      ],
      "metadata": {
        "id": "92u_gBxibFSp"
      }
    }
  ]
}